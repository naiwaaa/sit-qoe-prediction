---
jupyter:
  jupytext:
    cell_metadata_json: true
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.3.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

<!-- #region {"pycharm": {}, "heading_collapsed": true} -->
# Import
<!-- #endregion -->

```{python pycharm={'is_executing': False}, init_cell=TRUE, hidden=TRUE}
# %load_ext autoreload
# %autoreload 2
# %matplotlib inline
```

```{python pycharm={'is_executing': False}, init_cell=TRUE, hidden=TRUE}
import sys
import numpy as np
import matplotlib.pyplot as plt

from sit_qoe import data
from sit_qoe.data import splits, generate_timeseries
from sit_qoe.utils import visualize_qoe_predicted, metrics
from sit_qoe.models import QoE_CNN, QoE_TCN
```

```{python pycharm={}, init_cell=TRUE, hidden=TRUE}
from keras import backend as K

K.tensorflow_backend._get_available_gpus()
```

```{python hidden=TRUE}

```

<!-- #region {"heading_collapsed": true} -->
# Utilities Functions
<!-- #endregion -->

```{python init_cell=TRUE, hidden=TRUE}
SUPPORTED_DATASETS = ["lfovia", "live_mobile_stall_2", "live_netflix", "live_netflix_2"]
```

```{python init_cell=TRUE, hidden=TRUE}
def load_and_split_by_8020(dataset_index):
    (train, val, test), dataset_info = data.load(
        name=SUPPORTED_DATASETS[dataset_index],
        split=splits.TrainTestValRatioSplit(ratio=[0.8, 0.8], shuffle=False, random_state=23),
        with_info=True
    )
    print(
        f"{SUPPORTED_DATASETS[dataset_index]} loaded\n"
        f"Number of video data:\n"
        f"  train: {len(train)}\n"
        f"  test: {len(test)}\n"
        f"  val: {len(val)}\n"
    )
    return [[train, test, val]], dataset_info
```

```{python init_cell=TRUE, hidden=TRUE}
def load_and_split_by_pattern(dataset_index):
    dataset_split = None
    if dataset_index in [0, 2]:
        dataset_split = splits.TrainTestValPatternSplit(dataset_name=SUPPORTED_DATASETS[dataset_index])
    elif dataset_index == 1:
        dataset_split = splits.TrainTestValRandomSplit(random_state=23)
    elif dataset_index == 3:
        raise ValueError("live_netflix_2 pattern_split is not implemented.")

    dataset, dataset_info = data.load(
        name=SUPPORTED_DATASETS[dataset_index],
        split=dataset_split,
        with_info=True
    )
    print(
        f"{SUPPORTED_DATASETS[dataset_index]} loaded\n"
        f"Number of train-test-val sets: {len(dataset)}\n"
        f"Number of video data in each set:\n"
        f"  train: {len(dataset[0][0])}\n"
        f"  test: {len(dataset[0][1])}\n"
        f"  val: {len(dataset[0][2])}\n"
    )

    return dataset, dataset_info
```

```{python hidden=TRUE}

```

<!-- #region {"pycharm": {}} -->
# Load dataset
<!-- #endregion -->

Pattern split

```{python init_cell=TRUE}
# ["lfovia", "live_mobile_stall_2", "live_netflix", "live_netflix_2"]
dataset_index = 1
# change the index to switch to other QoE databases

train_test_sets, dataset_info = load_and_split_by_pattern(dataset_index)
dataset_info
```

80/20 split

```{python}
# ["lfovia", "live_mobile_stall_2", "live_netflix", "live_netflix_2"]
dataset_index = 0  # change the index to switch to other QoE databases

train_test_sets, dataset_info = load_and_split_by_8020(dataset_index)
dataset_info
```

Generate timeseries

```{python init_cell=TRUE}
split=(8, 1)
[
    generate_timeseries(train, dataset_info, normalize=True, split=split, split_method='less')
    for (train, test, val) in train_test_sets
]
[
    generate_timeseries(val, dataset_info, normalize=True, split=split, split_method='more')
    for (train, test, val) in train_test_sets
]
[
    generate_timeseries(test, dataset_info, normalize=True, split=split, split_method='more')
    for (train, test, val) in train_test_sets
]

print(f"Train shape: \n{train_test_sets[0][0].X.shape, train_test_sets[0][0].y.shape}")
print(f"Test shape: \n{train_test_sets[0][1].X.shape, train_test_sets[0][1].y.shape}")
print(f"Val shape: \n{train_test_sets[0][2].X.shape, train_test_sets[0][2].y.shape}")
```

```{python}
# maxlen = dataset_info["data_range"]["duration"][1]
split=(8, 1)
generate_timeseries(train_test_sets, dataset_info, normalize=True, split=split)

print(f"Train shape: \n{train_test_sets[0][0].X.shape, train_test_sets[0][0].y.shape}")
print(f"Test shape: \n{train_test_sets[0][1].X.shape, train_test_sets[0][1].y.shape}")
print(f"Val shape: \n{train_test_sets[0][2].X.shape, train_test_sets[0][2].y.shape}")
```

```{python}

```

<!-- #region {"pycharm": {}} -->
# Model
<!-- #endregion -->

```{python pycharm={}, init_cell=TRUE}
# he_normal, truncated_normal, glorot_uniform, he_uniform

def network_init(filters, split):
    model = QoE_CNN()

    model.construct_model(
        batch_size=None,
        timesteps=split[0],
        input_dim=train_test_sets[0][0].X.shape[2],
        filters=filters,
        kernel_size=3,
        dilations=[1, 2, 4],
        kernel_initializer="truncated_normal",
        return_sequences=False,
        learning_rate=0.001,
        activation='selu',
        use_skip_connections=False,       
    )
    model.summary()
    return model

# def network_init(filters, split):
#     model = QoE_TCN()

#     model.construct_model(
#         batch_size=None,
#         timesteps=split[0],
#         input_dim=train_test_sets[0][0].X.shape[2],
#         filters=filters,
#         kernel_size=3,
#         dilations=[1, 2, 4],
#         kernel_initializer="truncated_normal",
#         return_sequences=False,
#         learning_rate=0.001,
#         dropout=0.05,       
#     )
#     model.summary()
#     return model

model = network_init(32, split=split)
# model_one = network_init(1, split=split)
```

```{python}
model.load("/home/ndtho8205/Documents/Projects/SIT/sit_qoe/notebooks/saved_models/traintestsplit_lfovia_0_TV01_1080p30_1_7s.h5")
```

```{python}
model_name="test_flops"
model.save_weights(f"saved_models/{model_name}_weights.h5")

model_one.load_weights(f"saved_models/{model_name}_weights.h5")
model_one.save(f"saved_models/{model_name}.h5")
metrics.FLOPS_keras(f"saved_models/{model_name}.h5")
```

```{python}
metrics.FLOPS_pb("/home/ndtho8205/Documents/Projects/SIT/sit_qoe/android_app/QoEModel/app/src/main/assets/lstm/model/model_0.pb")
```

<!-- #region {"pycharm": {}} -->
# Evaluate
<!-- #endregion -->

<!-- #region {"pycharm": {}, "heading_collapsed": true} -->
## Train-test split - 1 samples
<!-- #endregion -->

```{python init_cell=TRUE, hidden=TRUE}
idx = 1
train, test, val = train_test_sets[idx]

print(len(train), len(test), len(val))
print(train.X.shape, test.X.shape, val.X.shape)
print(train.y.shape, test.y.shape, val.y.shape)
# (
#     train.map(lambda vd: vd.filename),
#     test.map(lambda vd: vd.filename),
#     val.map(lambda vd: vd.filename),
# )
```

```{python pycharm={}, hidden=TRUE}
model = network_init(32, split=split)

history = model.fit(
    train.X,
    train.y,
    epochs=500,
    shuffle=True,
    batch_size=64,
    verbose=2,
#     validation_split=0.2,
    validation_data=(val.X, val.y),
)
```

```{python pycharm={}, hidden=TRUE}
model.evaluate(test, verbose=1)

f, axs = plt.subplots(1, 2, figsize=(12, 6))
f.subplots_adjust(hspace=0.3)

model.visualize_learning_curves(axs[0])

visualize_qoe_predicted(
    axs[1],
    test.y.flatten()*100,
    model.predict(test.X).flatten()*100,
    test_video=test[0],
    legend=True,
    rebuff=False,
    tosec=False,
)
# axs[1].set_ylim([-2, 2])
```

```{python hidden=TRUE}
# %timeit model.predict(test.X[0:1, :, :])
```

```{python hidden=TRUE}

```

<!-- #region {"heading_collapsed": true} -->
## Parameters selection
<!-- #endregion -->

```{python hidden=TRUE}
grid_results = {}

for n_filters in [4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68]:
    results = []

    len_train_test_sets = len(train_test_sets)
    
    model = network_init(n_filters, batch_size=None, split=split)

    for idx in range(0, len_train_test_sets):
        sys.stdout.write(f"\r{idx + 1}/{len_train_test_sets}")

        train, test, val = train_test_sets[idx]
        
        model.fit(
            train.X,
            train.y,
            epochs=200,
            shuffle=True,
            batch_size=125,
            verbose=0,
            validation_data=(val.X, val.y),
        )

        results.append(model.evaluate(test, verbose=0))
        
    loss = np.mean([result["loss"] for result in results])
    srocc = np.mean([result["srocc"] for result in results])
    lcc = np.mean([result["pcc"] for result in results])
    rmse = np.mean([result["rmse"] for result in results])
    
    grid_results[n_filters] = {
        "loss": loss,
        "srocc": srocc,
        "lcc": lcc,
        "rmse": rmse,
    }
```

```{python hidden=TRUE}
print(grid_results)

# import json

# json = json.dumps(grid_results)
# f = open("grid_results_r8_nD2_selu.json","w")
# f.write(json)
# f.close()
```

```{python hidden=TRUE}
plt.ylim([0, 0.8])
plt.plot([k for (k, v) in grid_results.items()],
        [v['srocc'] for (k, v) in grid_results.items()])
plt.plot([k for (k, v) in grid_results.items()],
        [v['lcc'] for (k, v) in grid_results.items()])
plt.plot([k for (k, v) in grid_results.items()],
        [v['rmse'] for (k, v) in grid_results.items()])
```

```{python hidden=TRUE}

```

```{python hidden=TRUE}

```

## Train-test split - All dataset

```{python}
results = []
len_train_test_sets = len(train_test_sets)

for idx in range(0, len_train_test_sets):
    sys.stdout.write(f"\r{idx + 1}/{len_train_test_sets}")

    train, test, val = train_test_sets[idx]
    
    model = network_init(32, split=split)

    model.fit(
        train.X,
        train.y,
        epochs=500,
        shuffle=True,
        batch_size=64,
        verbose=0,
        validation_data=(val.X, val.y),
    )
    
#     model.load(
#         f"saved_models/traintestsplit_{dataset_info['id']}_{idx}_{test[0].filename}.h5"
#     )

    results.append(model.evaluate(test, verbose=0))

    model.save(
        f"saved_models/traintestsplit_{dataset_info['id']}_{idx}_{test[0].filename}.h5"
    )
```

```{python}
loss = [result["loss"] for result in results]
srocc = [result["srocc"] for result in results]
lcc = [result["pcc"] for result in results]
rmse = [result["rmse"] for result in results]

print(f"Loss:\t{np.mean(loss)} ± {np.std(loss)}")
print(f"SROCC:\t{np.mean(srocc)} ± {np.std(srocc)}")
print(f"LCC:\t{np.mean(lcc)} ± {np.std(lcc)}")
print(f"RMSE:\t{np.mean(rmse)} ± {np.std(rmse)}")
```

```{python}
test_indexes = np.argsort(rmse)[:8]

# lfovia
# array([ 6,  8,  5,  0, 22, 16,  1, 28])
# test_indexes = [ 8, 6,  0, 5]

# live_mobile
# array([14, 27, 13, 58, 12, 55, 65, 18])

#live_netflix
# array([12, 15,  2, 43, 14,  6, 13,  9])
test_indexes
```

```{python}
# test_indexes = range(0, len_train_test_sets - 26)
# test_indexes = np.argsort(rmse)[:8]  # range(0, 8)
test_indexes = [14, 27, 13, 58]

n_rows = np.ceil(len(test_indexes) / 4).astype("int")
n_cols = 4

fig, axs = plt.subplots(n_rows, n_cols, figsize=(18, 3), dpi=300)

for i, idx in enumerate(test_indexes):
    _, test, _ = train_test_sets[idx]
    model.load(
        f"saved_models/traintestsplit_{dataset_info['id']}_{idx}_{test[0].filename}.h5"
    )

    axis = axs[i % 4] if n_rows == 1 else axs[i // 4, i % 4]
    axis.set_title(f"Pattern #{i}")
    axis.set_ylim([0, 100])
    axis.set_yticks([0, 20, 40, 60, 80, 100])
    visualize_qoe_predicted(
        axis,
        test.y.flatten()*100,
        model.predict(test.X).flatten()*100,
        legend=False,
        ci=False,
#         tosec=True,
        test_video=test[0]
    )
    handles, labels = axis.get_legend_handles_labels()

fig.legend(handles, labels, loc="lower center", fancybox=False, shadow=False, ncol=3)
# fig.subplots_adjust(hspace=0.5, wspace=0.24, bottom=0.14)
fig.subplots_adjust(hspace=0.5, wspace=0.3, bottom=0.3)
fig.savefig(f"result_{dataset_info['id']}.png", bbox_inches="tight", pad_inches=0)
```

```{python}

```

## 80/20 split

```{python}
train, test, val = train_test_sets[0]
```

```{python}
model = network_init(32, split=split)

model.fit(
    train.X,
    train.y,
    epochs=1000,
    shuffle=True,
    batch_size=None,
    verbose=2,
    validation_data=(val.X, val.y),
)

model.save(f"saved_models/8020split_{dataset_info['id']}.h5")
```

```{python}
model.evaluate(test)
```

```{python}
model.evaluate()
```

```{python}
# test_indexes = range(0, len_train_test_sets - 26)
test_indexes = range(0, 8)

n_rows = np.ceil(len(test_indexes) / 4).astype("int")
n_cols = 4

fig, axs = plt.subplots(n_rows, n_cols, figsize=(18, 6), dpi=300)

for idx in test_indexes:
    axis = axs[idx % 4] if n_rows == 1 else axs[idx // 4, idx % 4]
    visualize_qoe_predicted(
        axis,
        test.y[idx : idx + 1],
        model.predict(test.X[idx : idx + 1]),
        test_video=test[idx],
        legend=False,
    )
    handles, labels = axis.get_legend_handles_labels()

fig.legend(handles, labels, loc="lower center", fancybox=False, shadow=False, ncol=3)
fig.subplots_adjust(hspace=0.4, wspace=0.24, bottom=0.17)
fig.savefig(f"result_{dataset_name}_8020.png", bbox_inches="tight", pad_inches=0)
```

```{python}

```

# Playground

```{python pycharm={}}
fig, axs = plt.subplots(2, 4, figsize=(22, 8))
# fig.subplots_adjust(hspace=0.3, wspace=0.24)

for i in range(test.y.shape[0]):
    y_pred = model.predict(test.X[i : i + 1])[0, :, 0]
    axis = axs[i // 4, i % 4]
    axis.set_title("QoE")
    axis.set_xlabel("Frame")
    axis.set_ylabel("QoE")
    axis.plot(
        test.y[i, : test_set[i].len_in_sec, 0], linestyle="--", label="Subjective QoE"
    )
    axis.plot(y_pred[: test_set[i].len_in_sec], label="Predicted QoE")
    axis.fill_between(
        range(0, test_set[i].len_in_sec),
        test_set[i].qoe_continuous.max(),
        test_set[i].qoe_continuous.min(),
        where=test_set[i].playback_indicator == 1,
        facecolor="#0F0F0F1F",
        label="Rebuffering",
        interpolate=True,
    )
    handles, labels = axis.get_legend_handles_labels()

fig.legend(handles, labels, loc="lower center", fancybox=False, shadow=False, ncol=4)

fig.subplots_adjust(hspace=0.3, wspace=0.2, bottom=0.12)

# fig.savefig('output1.png', bbox_inches='tight', pad_inches=0)
```

```{python pycharm={}}
f, axs = plt.subplots(2, 4, figsize=(15, 7), dpi=500)

for i in range(0, 8):
    axs[i // 4, i % 4].set_title(
        f"Pattern #{i} {'(no rebuffering)' if i in [0, 2, 4, 7] else ''}"
    )
    axs[i // 4, i % 4].set_xlabel("Frame")
    axs[i // 4, i % 4].set_ylabel("QoE")
    axs[i // 4, i % 4].set_ylim([-2, 2])
    axs[i // 4, i % 4].set_yticks([-2, -1, 0, 1, 2])
    axs[i // 4, i % 4].plot(
        y_result[i][0][: dataset[i].n_frames], label="Subjective QoE"
    )
    #     axs[i // 4, i % 4].fill_between(
    #         range(0, dataset[i].n_frames),
    #         y_result[i][0][:dataset[i].n_frames]*0.95,
    #         y_result[i][0][:dataset[i].n_frames]*1.05,
    #         color='blue',
    #         alpha=0.3,
    #         label='95% CI')
    axs[i // 4, i % 4].plot(
        y_result[i][1][: dataset[i].n_frames], "--", label="Predicted"
    )
    axs[i // 4, i % 4].legend()

f.subplots_adjust(hspace=0.3)
f.savefig("result.png", bbox_inches="tight", pad_inches=0)
```

```{python pycharm={}}

```

## Write file

```{python}

```

```{python}
train_test_sets[0][1].X.flatten().shape
```

```{python}
train_test_sets[0][1].X.shape
```

```{python}
results = []
len_train_test_sets = len(train_test_sets)

for idx in range(len_train_test_sets):
    sys.stdout.write(f"\r{idx + 1}/{len_train_test_sets}")

    train, test, val = train_test_sets[idx]
    np.savetxt(f"mobile/testX_{idx}_{test.X.shape[0]}_{test.X.shape[1]}_{test.X.shape[2]}.txt", test.X.flatten(), delimiter="\n")
    np.savetxt(f"mobile/testY_{idx}.txt", test.y.flatten(), delimiter="\n")
```

```{python}
from scipy.stats import pearsonr, spearmanr
from sklearn.metrics import mean_squared_error
from math import sqrt

LCC_test = []
SROCC_test = []
RMSE_test = []

actual_output = "/home/ndtho8205/Documents/Projects/SIT/sit_qoe/notebooks/mobile/lstm_accuracy_8020_comparePCvsMobile/actual_output"
mobile_output = "/home/ndtho8205/Documents/Projects/SIT/sit_qoe/notebooks/mobile/lstm_accuracy_8020_comparePCvsMobile/mobile_output"
for test_video_no in [1,2,3,5,8,15,23]:
    pred_QoE = np.loadtxt(f"{mobile_output}/output_{test_video_no}.txt")
    actual_QoE = np.loadtxt(f"{actual_output}/testY_{test_video_no}.txt")

    print(pred_QoE.shape, actual_QoE.shape)
    LCC_test.append(pearsonr(pred_QoE, actual_QoE))
    SROCC_test.append(spearmanr(pred_QoE, actual_QoE)[0])
    RMSE_test.append(sqrt(mean_squared_error(pred_QoE, actual_QoE)))

print(np.mean(LCC_test))
print(np.mean(SROCC_test))
print(np.mean(RMSE_test))
```

```{python}
train_test_sets[test_video_no][1][0].len_in_sec
```

```{python}
pred_tcn = np.loadtxt("./output_tcn.txt")
pred_qoecnn = np.loadtxt("./output_qoecnn.txt")
actual = np.loadtxt("./testY_0.txt")
from sit_qoe.utils import metrics

print(metrics.PCC(actual, pred_tcn), metrics.SROCC(actual, pred_tcn), metrics.RMSE(actual, pred_tcn))
print(metrics.PCC(actual, pred_qoecnn), metrics.SROCC(actual, pred_qoecnn), metrics.RMSE(actual, pred_qoecnn))
```

```{python}

```
